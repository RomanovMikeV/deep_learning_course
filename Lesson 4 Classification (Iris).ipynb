{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0#/media/File:Iris_dataset_scatterplot.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f448e330720>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import sklearn.datasets\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = sklearn.datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = iris.data[:, :2]\n",
    "labels = iris.target\n",
    "\n",
    "order = random.permutation(150)\n",
    "\n",
    "features = features[order, :]\n",
    "labels = labels[order]\n",
    "\n",
    "targets = numpy.zeros([150, 3])\n",
    "targets[arange(150), labels] = 1.0\n",
    "\n",
    "train_features = features[:100, :]\n",
    "test_features = features[100:, :]\n",
    "train_targets = targets[:100]\n",
    "test_targets = targets[100:]\n",
    "train_labels = labels[:100]\n",
    "test_labels = labels[100:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IrisNet(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        \n",
    "        super(IrisNet, self).__init__()\n",
    "        self.bn1 = torch.nn.BatchNorm1d(2)\n",
    "        self.fc1 = torch.nn.Linear(2, n_hidden_neurons)\n",
    "        self.activ1 = torch.nn.Sigmoid()\n",
    "        self.bn2 = torch.nn.BatchNorm1d(n_hidden_neurons)\n",
    "        self.fc2 = torch.nn.Linear(n_hidden_neurons, 3)\n",
    "        self.sm = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activ1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc2(x)\n",
    "#         x = self.activ2(x)\n",
    "        return x\n",
    "\n",
    "    def inference(self, x):\n",
    "        x = self.forward(x)\n",
    "        x = self.sm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "print train_targets.shape\n",
    "\n",
    "iris_net = IrisNet(5)\n",
    "\n",
    "optimizer = torch.optim.Adam(iris_net.parameters(), \n",
    "                             lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26\n",
      "0.86\n",
      "0.82\n",
      "0.82\n",
      "0.82\n",
      "0.82\n",
      "0.82\n",
      "0.84\n",
      "0.82\n",
      "0.82\n",
      "0.82\n",
      "0.8\n",
      "0.84\n",
      "0.84\n",
      "0.84\n",
      "0.84\n",
      "0.82\n",
      "0.82\n",
      "0.82\n",
      "0.82\n",
      "0.82\n",
      "0.8\n",
      "0.78\n",
      "0.78\n",
      "0.82\n",
      "0.78\n",
      "0.78\n",
      "0.76\n",
      "0.78\n",
      "0.78\n",
      "0.8\n",
      "0.78\n",
      "0.78\n",
      "0.78\n",
      "0.78\n",
      "0.78\n",
      "0.82\n",
      "0.78\n",
      "0.82\n",
      "0.78\n",
      "0.78\n",
      "0.78\n",
      "0.8\n",
      "0.78\n",
      "0.78\n",
      "0.78\n",
      "0.82\n",
      "0.8\n",
      "0.78\n",
      "0.8\n",
      "0.82\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.82\n",
      "0.82\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.78\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.82\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.82\n",
      "0.82\n",
      "0.82\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.82\n",
      "0.8\n",
      "0.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9f5cdad99707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wind/miniconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    143\u001b[0m                     'or with gradient w.r.t. the variable')\n\u001b[1;32m    144\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wind/miniconda2/lib/python2.7/site-packages/torch/nn/_functions/thnn/auto.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mupdate_grad_input_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_grad_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mgi_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_without_bias\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madditional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mupdate_grad_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgi_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mgrad_input_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrad_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "softmax = torch.nn.Softmax()\n",
    "\n",
    "for epoch in range(10000):\n",
    "    order = random.permutation(train_features.shape[0])\n",
    "    for start_index in range(0, train_features.shape[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_indice = order[start_index:start_index+batch_size]\n",
    "        \n",
    "        batch_features = torch.FloatTensor(train_features[batch_indice, :])\n",
    "        batch_labels = torch.LongTensor(train_labels[batch_indice])\n",
    "        \n",
    "        features_var = torch.autograd.Variable(batch_features)\n",
    "        targets_var = torch.autograd.Variable(batch_labels)\n",
    "        \n",
    "        preds_var = iris_net.forward(features_var)\n",
    "        \n",
    "#         print preds_var\n",
    "#         print targets_var\n",
    "        \n",
    "        loss = criterion.forward(preds_var, targets_var)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    test_features = torch.Tensor(test_features)\n",
    "    features_var = torch.autograd.Variable(test_features)\n",
    "    test_preds = iris_net.forward(features_var)\n",
    "    test_preds = softmax(test_preds).data.numpy()\n",
    "        \n",
    "    test_preds = test_preds.argmax(axis=1)\n",
    "    if epoch % 100 == 0:\n",
    "        print (test_preds == test_labels).sum() / float(test_labels.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "Сделать нейронную сеть с двумя скрытыми слоями (оба сигмоидные). Подобрать количество нейронов в первом и втором слое, которое максимизирует значение accuracy (процент угаданных цветков).\n",
    "\n",
    "Замените функцию активации с сигмоиды на гиперболический тангенс.\n",
    "Что изменилось?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2\n",
    "Отцентрируйте и отнормируйте данные, добавьте неиспользованные признаки. Стало ли качество лучше? Что больше повлияло на качество, предобработка данных или увеличение числа рассматриваемых признаков?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
